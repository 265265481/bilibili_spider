{
 "cells": [
  {
   "cell_type": "code",
   "id": "d08cc89f-48d7-4ef3-bdfb-d8b25c4346d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T02:42:32.934830Z",
     "start_time": "2025-08-05T02:42:15.530871Z"
    }
   },
   "source": [
    "# æ ¹æ®ç”¨æˆ·IDè·å¾—æŒ‡å®šæ—¶é—´æ®µçš„è§†é¢‘ä¿¡æ¯\n",
    "import requests\n",
    "import hashlib\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import jsonpath\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from urllib.parse import urlencode\n",
    "from openpyxl import Workbook, load_workbook\n",
    "import urllib.parse\n",
    "import traceback\n",
    "import random\n",
    "import threading\n",
    "\n",
    "# --- é…ç½®åŒºåŸŸ ---\n",
    "# è¯·åŠ¡å¿…ä¿®æ”¹è¿™é‡Œçš„é…ç½®\n",
    "CONFIG = {\n",
    "    # ç¡®ä¿è¿™ä¸ªExcelæ–‡ä»¶è·¯å¾„æ˜¯æ­£ç¡®çš„\n",
    "    # è¿™ä¸ªExcelæ–‡ä»¶åº”è¯¥åŒ…å«è¦è·å–UPä¸»MIDå·ï¼ŒMIDå·é»˜è®¤åœ¨ç¬¬ä¸€åˆ—ï¼ˆç´¢å¼•ä¸º0ï¼‰\n",
    "    \"excel_path\": r\"F:\\Code\\çˆ¬è™«\\UPä¸»ID.xlsx\",  # <--- è¯·æ›¿æ¢ä¸ºä½ çš„Excelæ–‡ä»¶è·¯å¾„\n",
    "\n",
    "    # Bç«™ç™»å½•Cookieå­—ç¬¦ä¸²æ± ï¼šé‡è¦ï¼ç”¨äºä¿æŒä¼šè¯ç¨³å®šæ€§å’Œåçˆ¬ã€‚è¯·æä¾›è‡³å°‘ä¸€ä¸ªæœ‰æ•ˆCookieã€‚\n",
    "    # è·å–æ–¹æ³•ï¼šç™»å½•Bç«™ -> F12å¼€å‘è€…å·¥å…· -> Network (ç½‘ç»œ) -> åˆ·æ–°é¡µé¢ -> æ‰¾åˆ°ä»»æ„è¯·æ±‚ -> Headers (è¯·æ±‚å¤´) -> Request Headers (è¯·æ±‚å¤´) ä¸­æ‰¾åˆ° 'Cookie' å­—æ®µï¼Œå¤åˆ¶å…¶å®Œæ•´å†…å®¹ã€‚\n",
    "    \"cookie_strings_pool\": [\n",
    "        \"buvid3=384BBEAA-858B-A2E9-5B83-849BC33FA9C630622infoc; b_nut=1741237430; _uuid=4BBF9EA4-1FE10-3ECA-B936-D37E18A4104B730789infoc; enable_web_push=DISABLE; buvid4=3EC2F346-3DDE-A9E7-79EC-DD96376E9C5931240-025030605-UEW7z%2Frhc9FUd5uaNwO%2FDQ%3D%3D; buvid_fp=0f85c81c4fa8403529178b71f34e4055; rpdid=0zbfVJ1vzQ|7Qh8tt0I|2lF|3w1U6854; enable_feed_channel=ENABLE; theme-tip-show=SHOWED; theme-avatar-tip-show=SHOWED; theme-switch-show=SHOWED; bp_t_offset_355987571=1087855640585437184; header_theme_version=OPEN; bp_t_offset_435641086=1092808085770076160; b_lsid=C5FCC3FF_1987818959F; bsource=search_bing; bili_ticket=eyJhbGciOiJIUzI1NiIsImtpZCI6InMwMyIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3NTQ2MjA3MzIsImlhdCI6MTc1NDM2MTQ3MiwicGx0IjotMX0.HthfuyxINbFh1eFX5wF4oQ4exeKxXVeadrliEFJQJs4; bili_ticket_expires=1754620672; bp_t_offset_3493111795812748=1097463538261164032; CURRENT_FNVAL=2000; csrf_state=a2a7469d11ecb38b0cf9dc6600a52207; SESSDATA=720472af%2C1769913559%2Ccf013%2A82CjDtXnMmG5j4aZlVtvGckgP6ZiLzw9NpGJNtXFdWCasXC0Gi-LK17RfYB5OJH4EGhzESVmlPaEVUQW1rc0pLc0VLdDVtc2p2Tlp6ZVR5c25EQXZnc1NjRVFOcU0yOGtTQV9BVldzdUFvbGtDODZEWjZ6VC1OUW5uMl9ZQ1Z3a2Y5UU93VWE1UHFBIIEC; bili_jct=71f8500b3f14f993f7c50a54de0638cd; DedeUserID=3546919328549020; DedeUserID__ckMd5=34f98e6ac83665d9; sid=5awtpcjx; bp_t_offset_3546919328549020=1097463632750444544; home_feed_column=4; browser_resolution=763-834\"# å¯ä»¥æ·»åŠ æ›´å¤šCookieå­—ç¬¦ä¸²\n",
    "    ],\n",
    "    \"cookie_rotate_interval_seconds\": 900,  # Cookieè½®æ¢é—´éš”ï¼Œå•ä½ç§’ (900ç§’ = 15åˆ†é’Ÿ)\n",
    "\n",
    "    # è§†é¢‘æ—¶é—´ç­›é€‰èŒƒå›´ 2023å¹´7æœˆ1æ—¥è‡³2024å¹´1æœˆ31æ—¥\n",
    "    \"start_date\": \"2023-07-01\",  # å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD\n",
    "    \"end_date\": \"2024-01-31\",  # ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD\n",
    "\n",
    "    # æ‰¹é‡å¤„ç†UPä¸»çš„èŒƒå›´ï¼ˆä»Excelä¸­è¯»å–UPä¸»åˆ—è¡¨çš„ç´¢å¼•ï¼‰\n",
    "    \"start_index\": 750,  # å¼€å§‹ä½ç½®ï¼ˆä»0å¼€å§‹ï¼‰\n",
    "    \"end_index\": None,  # ç»“æŸä½ç½®ï¼ˆNoneè¡¨ç¤ºåˆ°æ–‡ä»¶æœ«å°¾ï¼‰\n",
    "\n",
    "    # æ¯ä¸ªUPä¸»æœ€å¤§çˆ¬å–é¡µæ•°ï¼šBç«™è§†é¢‘åˆ—è¡¨æ¯é¡µ40ä¸ªï¼Œå¯ä»¥æ ¹æ®UPä¸»è§†é¢‘æ•°é‡å’Œéœ€è¦è®¾å®šã€‚\n",
    "    \"max_pages_per_up\": 20,\n",
    "}\n",
    "\n",
    "def sanitize_filename(name):\n",
    "    \"\"\"ç§»é™¤æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦\"\"\"\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"\", name)\n",
    "\n",
    "def read_up_list_from_excel(file_path, start_index=0, end_index=None):\n",
    "    try:\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"âŒ é”™è¯¯: '{file_path}' æ–‡ä»¶ä¸å­˜åœ¨!\")\n",
    "            return []\n",
    "        print(f\"ğŸ“Š æ­£åœ¨è¯»å–Excelæ–‡ä»¶: {file_path}\")\n",
    "        df = pd.read_excel(file_path)\n",
    "\n",
    "        up_mids = df.iloc[:, 0].tolist()  # è·å–ç¬¬ä¸€åˆ—æ•°æ®\n",
    "\n",
    "        up_mids = [str(mid).strip() for mid in up_mids if pd.notna(mid) and str(mid).strip()]\n",
    "\n",
    "        # ç§»é™¤å¯èƒ½çš„è¡¨å¤´ï¼ˆå¦‚æœç¬¬ä¸€è¡Œæ˜¯å­—ç¬¦ä¸²è€Œä¸æ˜¯MIDï¼‰\n",
    "        if up_mids and not up_mids[0].isdigit():  \n",
    "            up_mids = up_mids[1:]\n",
    "\n",
    "        total_count = len(up_mids)\n",
    "        print(f\"âœ… æˆåŠŸè¯»å–åˆ° {total_count} ä¸ªUPä¸»IDã€‚\")\n",
    "\n",
    "        # åº”ç”¨ç´¢å¼•èŒƒå›´\n",
    "        if end_index is None:\n",
    "            end_index = total_count\n",
    "        else:\n",
    "            end_index = min(end_index, total_count)\n",
    "        \n",
    "        start_index = max(0, start_index)  # ç¡®ä¿start_indexä¸ä¸ºè´Ÿ\n",
    "\n",
    "        if start_index >= total_count and total_count > 0:  # å¦‚æœæ–‡ä»¶éç©ºä½†èµ·å§‹ç´¢å¼•è¶…å‡º\n",
    "            print(f\"âš ï¸ æŒ‡å®šçš„å¼€å§‹ç´¢å¼• {start_index} è¶…å‡ºExcelä¸­UPä¸»IDçš„æ€»æ•° {total_count}ã€‚\")\n",
    "            return []\n",
    "        elif total_count == 0:  # æ–‡ä»¶ä¸ºç©ºæˆ–æ— æœ‰æ•ˆæ•°æ®\n",
    "            print(\"âš ï¸ Excelæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„UPä¸»IDã€‚\")\n",
    "            return []\n",
    "\n",
    "\n",
    "        selected_up_mids = up_mids[start_index:end_index]\n",
    "\n",
    "        print(f\"ğŸ¯ é€‰æ‹©å¤„ç†èŒƒå›´: [{start_index}:{end_index}]ï¼Œå…± {len(selected_up_mids)} ä¸ªUPä¸»ã€‚\")\n",
    "        return selected_up_mids\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è¯»å–Excelæ–‡ä»¶å¤±è´¥: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def write_results_to_excel(df: pd.DataFrame, file_path: str):\n",
    "    try:\n",
    "        df.to_excel(file_path, index=False)\n",
    "        print(f\"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ° '{file_path}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ å†™å…¥Excelå‡ºé”™: {str(e)}\")\n",
    "\n",
    "class BilibiliCrawler:\n",
    "    DEFAULT_REQUEST_TIMEOUT = 60  # è¯·æ±‚è¶…æ—¶æ—¶é—´\n",
    "    DEFAULT_RETRY_COUNT = 5  # é‡è¯•æ¬¡æ•°\n",
    "    DEFAULT_BACKOFF_FACTOR = 9  # é‡è¯•é—´éš”å› å­ (1s, 3s, 9s, ...)\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "        self.cookie_strings_pool = config[\"cookie_strings_pool\"]\n",
    "        self.cookie_rotate_interval_seconds = config[\"cookie_rotate_interval_seconds\"]\n",
    "        self.current_cookie_index = 0\n",
    "        self.last_cookie_change_time = time.time()\n",
    "        self.cookies = {}  # requests library cookie jar\n",
    "        \n",
    "        # User-Agentæ± \n",
    "        self.user_agent_pool = [\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',\n",
    "            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:128.0) Gecko/20100101 Firefox/128.0',\n",
    "            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:128.0) Gecko/20100101 Firefox/128.0',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/126.0.2592.56',\n",
    "            'Mozilla/5.0 (Linux; Android 14) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.6478.140 Mobile Safari/537.36',\n",
    "            'Mozilla/5.0 (iPhone; CPU iPhone OS 17_5_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.5 Mobile/15E148 Safari/604.1',\n",
    "        ]\n",
    "\n",
    "        self.headers = {\n",
    "            'Accept': 'application/json, text/plain, */*',\n",
    "            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',\n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Referer': 'https://space.bilibili.com/',\n",
    "            'Origin': 'https://space.bilibili.com',\n",
    "            'Sec-Fetch-Dest': 'empty',\n",
    "            'Sec-Fetch-Mode': 'cors',\n",
    "            'Sec-Fetch-Site': 'same-site',\n",
    "            'Cookie': ''  # åˆå§‹ä¸ºç©ºï¼Œç”±_set_current_cookieè®¾ç½®\n",
    "        }\n",
    "        \n",
    "        self.wbi_keys = None  # ç”¨äºè§†é¢‘åˆ—è¡¨APIçš„WBIå¯†é’¥\n",
    "        self.mixinKeyEncTab = [  # WBIç­¾åç”¨åˆ°çš„å›ºå®šæ•°ç»„\n",
    "            46, 47, 18, 2, 53, 8, 23, 32, 15, 50, 10, 31, 58, 3, 45, 35, 27, 43, 5, 49,\n",
    "            33, 9, 42, 19, 29, 28, 14, 39, 12, 38, 41, 13, 37, 48, 7, 16, 24, 55, 40,\n",
    "            61, 26, 17, 0, 1, 60, 51, 30, 4, 22, 25, 54, 21, 56, 59, 6, 63, 57, 62, 11,\n",
    "            36, 20, 34, 44, 52\n",
    "        ]\n",
    "\n",
    "        # åˆå§‹åŒ–æ—¶è®¾ç½®ç¬¬ä¸€ä¸ª Cookie\n",
    "        self._set_current_cookie()  \n",
    "\n",
    "        # ç»Ÿè®¡æ•°æ®\n",
    "        self.batch_stats = {\n",
    "            'total_processed': 0,\n",
    "            'success_count': 0,\n",
    "            'failed_count': 0,\n",
    "            'total_videos': 0,\n",
    "        }\n",
    "\n",
    "        # æ—¶é—´ç­›é€‰èŒƒå›´\n",
    "        self.start_timestamp = int(datetime.datetime.strptime(config[\"start_date\"], \"%Y-%m-%d\").timestamp())\n",
    "        self.end_timestamp = int(datetime.datetime.strptime(config[\"end_date\"] + \" 23:59:59\", \"%Y-%m-%d %H:%M:%S\").timestamp())\n",
    "        self.start_date = config[\"start_date\"]\n",
    "        self.end_date = config[\"end_date\"]\n",
    "\n",
    "    def _parse_cookies(self, cookie_string):\n",
    "        \"\"\"è§£æcookieå­—ç¬¦ä¸²ä¸ºå­—å…¸\"\"\"\n",
    "        cookies = {}\n",
    "        for item in cookie_string.split(';'):\n",
    "            if '=' in item:\n",
    "                key, value = item.strip().split('=', 1)\n",
    "                cookies[key] = value\n",
    "        return cookies\n",
    "\n",
    "    def _set_current_cookie(self):\n",
    "        \"\"\"è®¾ç½®å½“å‰ä½¿ç”¨çš„ Cookie\"\"\"\n",
    "        if not self.cookie_strings_pool:\n",
    "            print(\"âŒ Cookieæ± ä¸ºç©ºï¼Œå°†æ— æ³•è¿›è¡ŒCookieè½®æ¢ã€‚\")\n",
    "            self.cookies = {}  # requests library cookie jar\n",
    "            self.headers['Cookie'] = \"\"  # http header cookie string\n",
    "            return\n",
    "\n",
    "        cookie_string = self.cookie_strings_pool[self.current_cookie_index]\n",
    "        self.cookies = self._parse_cookies(cookie_string)\n",
    "        self.headers['Cookie'] = cookie_string  \n",
    "        self.last_cookie_change_time = time.time()\n",
    "        print(f\"âœ… Cookieå·²åˆ‡æ¢è‡³æ± ä¸­ç´¢å¼• {self.current_cookie_index} çš„Cookieã€‚\")\n",
    "\n",
    "    def _rotate_cookie_if_needed(self):\n",
    "        \"\"\"æ ¹æ®æ—¶é—´é—´éš”è½®æ¢Cookie\"\"\"\n",
    "        if not self.cookie_strings_pool or len(self.cookie_strings_pool) <= 1:\n",
    "            return\n",
    "\n",
    "        if (time.time() - self.last_cookie_change_time) >= self.cookie_rotate_interval_seconds:\n",
    "            self.current_cookie_index = (self.current_cookie_index + 1) % len(self.cookie_strings_pool)\n",
    "            self._set_current_cookie()\n",
    "            print(f\"ğŸ”„ Cookie è¾¾åˆ° {self.cookie_rotate_interval_seconds} ç§’è½®æ¢å‘¨æœŸï¼Œå·²åˆ‡æ¢åˆ°æ–° Cookie (ç´¢å¼•: {self.current_cookie_index})ã€‚\")\n",
    "\n",
    "    def _make_request(self, url, method=\"GET\", params=None, data=None, json_data=None, extra_headers=None):\n",
    "        self._rotate_cookie_if_needed()  # æ¯æ¬¡è¯·æ±‚å‰æ£€æŸ¥å¹¶è½®æ¢Cookie\n",
    "\n",
    "        current_attempt = 0\n",
    "        request_headers = self.headers.copy()  # headerså·²åŒ…å«User-Agentå’Œå½“å‰Cookie\n",
    "\n",
    "        request_headers['User-Agent'] = random.choice(self.user_agent_pool)  # éšæœºé€‰æ‹©User-Agent\n",
    "\n",
    "        if extra_headers:\n",
    "            request_headers.update(extra_headers)\n",
    "\n",
    "        while current_attempt < self.DEFAULT_RETRY_COUNT:  # ä½¿ç”¨ç±»å±æ€§\n",
    "            try:\n",
    "                if method.upper() == \"GET\":\n",
    "                    response = requests.get(\n",
    "                        url,\n",
    "                        headers=request_headers,\n",
    "                        cookies=self.cookies,  # ä½¿ç”¨self.cookieså¯¹è±¡ï¼Œå®ƒä¼šåœ¨_set_current_cookieä¸­æ›´æ–°\n",
    "                        params=params,\n",
    "                        timeout=self.DEFAULT_REQUEST_TIMEOUT  # ä½¿ç”¨ç±»å±æ€§\n",
    "                    )\n",
    "                elif method.upper() == \"POST\":\n",
    "                    response = requests.post(\n",
    "                        url,\n",
    "                        headers=request_headers,\n",
    "                        cookies=self.cookies,  # ä½¿ç”¨self.cookieså¯¹è±¡\n",
    "                        params=params,\n",
    "                        data=data,\n",
    "                        json=json_data,\n",
    "                        timeout=self.DEFAULT_REQUEST_TIMEOUT  # ä½¿ç”¨ç±»å±æ€§\n",
    "                    )\n",
    "                else:\n",
    "                    raise ValueError(f\"ä¸æ”¯æŒçš„HTTPæ–¹æ³•: {method}\")\n",
    "\n",
    "                if response.status_code == 200:\n",
    "                    return response\n",
    "                elif response.status_code in [403, 412, 429, 500, 502, 503, 504]:\n",
    "                    print(f\"HTTPé”™è¯¯: {response.status_code}. å°è¯•é‡è¯•...\")\n",
    "                    time.sleep(self.DEFAULT_BACKOFF_FACTOR ** current_attempt)  # ä½¿ç”¨ç±»å±æ€§\n",
    "                else:\n",
    "                    print(f\"é200 HTTPçŠ¶æ€ç : {response.status_code}.\")\n",
    "                    return response\n",
    "\n",
    "            except requests.exceptions.Timeout:\n",
    "                print(\"è¯·æ±‚è¶…æ—¶ã€‚å°è¯•é‡è¯•...\")\n",
    "                time.sleep(self.DEFAULT_BACKOFF_FACTOR ** current_attempt)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"è¯·æ±‚å¼‚å¸¸: {e}. å°è¯•é‡è¯•...\")\n",
    "                time.sleep(self.DEFAULT_BACKOFF_FACTOR ** current_attempt)\n",
    "            except Exception as e:\n",
    "                print(f\"æœªçŸ¥é”™è¯¯: {e}.\")\n",
    "                return None\n",
    "\n",
    "            current_attempt += 1\n",
    "\n",
    "        print(f\"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè¯·æ±‚å¤±è´¥: {url}\")\n",
    "        return None\n",
    "\n",
    "    def test_cookie_validity(self):\n",
    "        \"\"\"æµ‹è¯•Cookieæ± ä¸­å½“å‰Cookieçš„æœ‰æ•ˆæ€§\"\"\"\n",
    "        test_url = \"https://api.bilibili.com/x/web-interface/nav\"\n",
    "        \n",
    "        # ä½¿ç”¨å½“å‰åŠ è½½åˆ°self.cookieså’Œself.headers['Cookie']çš„Cookieè¿›è¡Œæµ‹è¯•\n",
    "        response = self._make_request(test_url)\n",
    "\n",
    "        if response and response.status_code == 200:\n",
    "            try:\n",
    "                data = response.json()\n",
    "                if data.get('code') == 0:\n",
    "                    user_info = data.get('data', {})\n",
    "                    return True, {\n",
    "                        'username': user_info.get('uname', 'æœªçŸ¥'),\n",
    "                        'uid': user_info.get('mid', 'æœªçŸ¥'),\n",
    "                        'level': user_info.get('level_info', {}).get('current_level', 0),\n",
    "                        'coins': user_info.get('money', 0),\n",
    "                        'vip_status': user_info.get('vipStatus', 0)\n",
    "                    }\n",
    "                else:\n",
    "                    return False, f\"APIè¿”å›é”™è¯¯: {data.get('message', 'æœªçŸ¥é”™è¯¯')} (Code: {data.get('code')})\"\n",
    "            except json.JSONDecodeError:\n",
    "                return False, \"æ— æ³•è§£æCookieæµ‹è¯•APIçš„å“åº”ä¸ºJSONã€‚\"\n",
    "        else:\n",
    "            status_code = response.status_code if response else 'N/A'\n",
    "            return False, f\"HTTPè¯·æ±‚å¤±è´¥æˆ–æ— å“åº”ï¼ŒçŠ¶æ€ç : {status_code}\"\n",
    "\n",
    "    # --- Bç«™WBIç­¾åç®—æ³• (ç”¨äºè§†é¢‘åˆ—è¡¨å’Œè¯¦æƒ…) ---\n",
    "    def get_mixin_key(self, orig: str) -> str:\n",
    "        return ''.join([orig[i] for i in self.mixinKeyEncTab])[:32]\n",
    "\n",
    "    def enc_wbi(self, params: dict, img_key: str, sub_key: str) -> dict:\n",
    "        mixin_key = self.get_mixin_key(img_key + sub_key)\n",
    "        curr_time = round(time.time())\n",
    "        params['wts'] = curr_time\n",
    "\n",
    "        sorted_params = sorted(params.items())\n",
    "        query = urlencode(sorted_params)\n",
    "\n",
    "        wbi_sign = hashlib.md5((query + mixin_key).encode()).hexdigest()\n",
    "        params['w_rid'] = wbi_sign\n",
    "        return params\n",
    "\n",
    "    def get_wbi_keys(self):\n",
    "        # ä¼˜åŒ–ï¼šæ¯æ¬¡åªåœ¨éœ€è¦æ—¶æ‰è·å– WBI å¯†é’¥ï¼Œå¹¶ç¼“å­˜\n",
    "        if hasattr(self, '_cached_wbi_keys') and self._cached_wbi_keys:\n",
    "            return self._cached_wbi_keys\n",
    "\n",
    "        response = self._make_request(\n",
    "            'https://api.bilibili.com/x/web-interface/nav'\n",
    "        )\n",
    "\n",
    "        if response and response.status_code == 200:\n",
    "            try:\n",
    "                json_content = response.json()\n",
    "                if json_content.get('code') == 0:\n",
    "                    wbi_img = json_content['data']['wbi_img']\n",
    "                    img_url: str = wbi_img['img_url']\n",
    "                    sub_url: str = wbi_img['sub_url']\n",
    "                    img_key = img_url.rsplit('/', 1)[1].split('.')[0]\n",
    "                    sub_key = sub_url.rsplit('/', 1)[1].split('.')[0]\n",
    "                    self._cached_wbi_keys = (img_key, sub_key)  # ç¼“å­˜å¯†é’¥\n",
    "                    return img_key, sub_key\n",
    "                else:\n",
    "                    print(f\"è·å–WBIå¯†é’¥å¤±è´¥ï¼ˆAPIé”™è¯¯ï¼‰: {json_content.get('message')} (Code: {json_content.get('code')})\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"è·å–WBIå¯†é’¥å“åº”JSONè§£æå¤±è´¥ã€‚\")\n",
    "        else:\n",
    "            status_code = response.status_code if response else 'N/A'\n",
    "            print(f\"è·å–WBIå¯†é’¥HTTPè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {status_code}\")\n",
    "\n",
    "        return None, None\n",
    "\n",
    "    def generate_api_url(self, mid, page=1, ps=40):\n",
    "        if not self.wbi_keys:\n",
    "            img_key, sub_key = self.get_wbi_keys()\n",
    "            if not img_key or not sub_key:\n",
    "                print(\"âŒ æ— æ³•ç”Ÿæˆè§†é¢‘åˆ—è¡¨APIçš„wbiå¯†é’¥\")\n",
    "                return None\n",
    "            self.wbi_keys = (img_key, sub_key)\n",
    "        else:\n",
    "            img_key, sub_key = self.wbi_keys\n",
    "\n",
    "        params = {\n",
    "            'mid': str(mid),\n",
    "            'ps': str(ps),\n",
    "            'tid': '0',\n",
    "            'pn': str(page),\n",
    "            'keyword': '',\n",
    "            'order': 'pubdate',\n",
    "            'platform': 'web',\n",
    "            'web_location': '333.1387',\n",
    "            'order_avoided': 'true'\n",
    "        }\n",
    "\n",
    "        signed_params = self.enc_wbi(params, img_key, sub_key)\n",
    "        base_url = \"https://api.bilibili.com/x/space/wbi/arc/search\"\n",
    "        url = f\"{base_url}?{urlencode(signed_params)}\"\n",
    "\n",
    "        return url\n",
    "\n",
    "    # --- è·å–UPä¸»ä¿¡æ¯ ---\n",
    "    def get_up_info(self, mid):\n",
    "        # æ–¹æ¡ˆ1: å°è¯•è·å–è¯¦ç»†ä¿¡æ¯ (éœ€è¦wbi)\n",
    "        url = f\"https://api.bilibili.com/x/space/wbi/acc/info?mid={mid}\"\n",
    "        response = self._make_request(url)\n",
    "\n",
    "        if response and response.status_code == 200:\n",
    "            try:\n",
    "                data = response.json()\n",
    "                if data.get('code') == 0:\n",
    "                    return data['data']\n",
    "                else:\n",
    "                    print(f\"è¯¦ç»†ä¿¡æ¯è·å–å¤±è´¥: {data.get('message', 'æœªçŸ¥é”™è¯¯')} (Code: {data.get('code')})\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"è¯¦ç»†ä¿¡æ¯å“åº”JSONè§£æå¤±è´¥ã€‚\")\n",
    "\n",
    "        # æ–¹æ¡ˆ2: å°è¯•è·å–åŸºç¡€ä¿¡æ¯ (å¯èƒ½ä¸éœ€è¦wbi)\n",
    "        print(\"ğŸ”„ å°è¯•è·å–åŸºç¡€UPä¸»ä¿¡æ¯...\")\n",
    "        basic_url = f\"https://api.bilibili.com/x/space/acc/info?mid={mid}\"\n",
    "        response = self._make_request(basic_url)\n",
    "\n",
    "        if response and response.status_code == 200:\n",
    "            try:\n",
    "                data = response.json()\n",
    "                if data.get('code') == 0:\n",
    "                    return data['data']\n",
    "                else:\n",
    "                    print(f\"åŸºç¡€ä¿¡æ¯è·å–å¤±è´¥: {data.get('message', 'æœªçŸ¥é”™è¯¯')} (Code: {data.get('code')})\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"åŸºç¡€ä¿¡æ¯å“åº”JSONè§£æå¤±è´¥ã€‚\")\n",
    "\n",
    "        # æ–¹æ¡ˆ3: ä»è§†é¢‘é¡µé¢è·å–ä¿¡æ¯ (å¦‚æœå‰ä¸¤è€…éƒ½å¤±è´¥)\n",
    "        try:\n",
    "            print(\"ğŸ”„ å°è¯•ä»è§†é¢‘é¡µé¢è·å–UPä¸»ä¿¡æ¯...\")\n",
    "            first_url = self.generate_api_url(mid, 1)\n",
    "            if first_url:\n",
    "                response = self._make_request(first_url)\n",
    "                if response and response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    if data.get('code') == 0:\n",
    "                        vlist = data.get('data', {}).get('list', {}).get('vlist', [])\n",
    "                        if vlist:\n",
    "                            first_video = vlist[0]\n",
    "                            return {\n",
    "                                'name': first_video.get('author', f'UPä¸»{mid}'),\n",
    "                                'mid': mid,\n",
    "                                'follower': 0,\n",
    "                                'video': len(vlist)\n",
    "                            }\n",
    "            print(\"âŒ ä»è§†é¢‘é¡µé¢è·å–UPä¸»ä¿¡æ¯å¤±è´¥ã€‚\")\n",
    "        except Exception as e:\n",
    "            print(f\"ä»è§†é¢‘é¡µé¢è·å–ä¿¡æ¯æ—¶å‘ç”Ÿå¼‚å¸¸: {e}\")\n",
    "\n",
    "        return None\n",
    "\n",
    "    # --- è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…å«æ’­æ”¾ã€ç‚¹èµã€æ”¶è—ç­‰ï¼‰ ---\n",
    "    def get_video_detail(self, aid):\n",
    "        if not aid:\n",
    "            return None\n",
    "\n",
    "        url = \"https://api.bilibili.com/x/web-interface/wbi/view/detail\"\n",
    "        if not self.wbi_keys:\n",
    "            self.get_wbi_keys()\n",
    "        if not self.wbi_keys:\n",
    "            print(\"âŒ æ— æ³•è·å–è§†é¢‘è¯¦æƒ…APIçš„wbiå¯†é’¥ï¼Œè·³è¿‡è¯¦æƒ…è·å–ã€‚\")\n",
    "            return None\n",
    "\n",
    "        img_key, sub_key = self.wbi_keys\n",
    "        params = {\"aid\": aid}\n",
    "        signed_params = self.enc_wbi(params, img_key, sub_key)\n",
    "\n",
    "        response = self._make_request(\n",
    "            url,\n",
    "            params=signed_params\n",
    "        )\n",
    "\n",
    "        if not response or response.status_code != 200:\n",
    "            print(f\"è·å–è§†é¢‘ {aid} è¯¦æƒ…å¤±è´¥ï¼ŒHTTPçŠ¶æ€ç : {response.status_code if response else 'N/A'}\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            json_data = response.json()\n",
    "            if json_data.get('code') != 0:\n",
    "                print(f\"è¯¦æƒ…APIè¿”å›é”™è¯¯: {json_data.get('message', 'æœªçŸ¥é”™è¯¯')} (Code: {json_data.get('code')})\")\n",
    "                return None\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"è¯¦æƒ…JSONè§£æå¤±è´¥\")\n",
    "            return None\n",
    "\n",
    "        view = jsonpath.jsonpath(json_data, '$..View.stat')\n",
    "        tags = jsonpath.jsonpath(json_data, '$..Tags')\n",
    "        Cards = jsonpath.jsonpath(json_data, '$..Card..card')\n",
    "        duration_seconds_list = jsonpath.jsonpath(json_data, '$..View.duration')\n",
    "        duration_seconds = duration_seconds_list[0] if duration_seconds_list else 'N/A'\n",
    "\n",
    "        pages_list = jsonpath.jsonpath(json_data, '$..View.pages')\n",
    "        pages_count = len(pages_list[0]) if pages_list and pages_list[0] else 0\n",
    "\n",
    "        copyright_val = jsonpath.jsonpath(json_data, '$..View.copyright')\n",
    "        copyright = 'åŸåˆ›' if copyright_val and copyright_val[0] == 1 else 'è½¬è½½'\n",
    "\n",
    "        video_state_val = jsonpath.jsonpath(json_data, '$..View.state')\n",
    "        video_state = video_state_val[0] if video_state_val else 'N/A'\n",
    "\n",
    "        related_list = jsonpath.jsonpath(json_data, '$..Related')\n",
    "        related_count = len(related_list[0]) if related_list and related_list[0] else 0\n",
    "\n",
    "        mid = name = fans = sign = Official = level_info = 'N/A'\n",
    "        sex = vip_type = vip_status = nameplate = 'N/A'\n",
    "\n",
    "        if Cards:\n",
    "            card_data = Cards[0]\n",
    "            mid = card_data.get('mid', 'N/A')\n",
    "            name = card_data.get('name', 'N/A')\n",
    "            fans = card_data.get('fans', 'N/A')\n",
    "            sign = card_data.get('sign', 'N/A')\n",
    "            sex = card_data.get('sex', 'N/A')\n",
    "\n",
    "            if card_data.get('Official'):\n",
    "                Official = card_data.get('Official').get('title', '')\n",
    "            if card_data.get('level_info'):\n",
    "                level_info = f\"{Official}/{card_data.get('level_info').get('current_level')}\"\n",
    "\n",
    "            vip_data = card_data.get('vip', {})\n",
    "            vip_type_val = vip_data.get('type')\n",
    "            if vip_type_val == 1:\n",
    "                vip_type = 'æœˆåº¦å¤§ä¼šå‘˜'\n",
    "            elif vip_type_val == 2:\n",
    "                vip_type = 'å¹´åº¦åŠä»¥ä¸Šå¤§ä¼šå‘˜'\n",
    "            else:\n",
    "                vip_type = 'æ— '\n",
    "            vip_status = 'æœ‰æ•ˆ' if vip_data.get('status') == 1 else 'æ— æ•ˆ'\n",
    "\n",
    "            nameplate_data = card_data.get('nameplate', {})\n",
    "            nameplate = nameplate_data.get('name', 'æ— ')\n",
    "\n",
    "        region = 'N/A'\n",
    "        if tags and tags[0]:\n",
    "            region_list = [tag.get('tag_name') for tag in tags[0]]\n",
    "            region = 'ã€'.join(region_list)\n",
    "\n",
    "        like = collect = coin = share = 'N/A'\n",
    "        if view:\n",
    "            view_data = view[0]\n",
    "            like = view_data.get('like', 'N/A')\n",
    "            collect = view_data.get('favorite', 'N/A')\n",
    "            coin = view_data.get('coin', 'N/A')\n",
    "            share = view_data.get('share', 'N/A')\n",
    "\n",
    "        return (like, collect, coin, share, region, mid, name, fans, sign, level_info, duration_seconds,\n",
    "                pages_count, copyright, video_state, related_count, sex, vip_type, vip_status, nameplate)\n",
    "\n",
    "    # --- æ—¶é—´ç­›é€‰ç›¸å…³åŠŸèƒ½ ---\n",
    "    def is_video_in_time_range(self, created_timestamp):\n",
    "        return self.start_timestamp <= created_timestamp <= self.end_timestamp\n",
    "\n",
    "    def format_timestamp(self, timestamp):\n",
    "        return datetime.datetime.fromtimestamp(timestamp).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    def timestamp_to_datetime(self, timestamp):\n",
    "        dt_object = datetime.datetime.fromtimestamp(timestamp)\n",
    "        return dt_object.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # --- è§†é¢‘åˆ—è¡¨çˆ¬å–é€»è¾‘ ---\n",
    "    def get_filtered_videos_from_url(self, url):\n",
    "        response = self._make_request(url)\n",
    "\n",
    "        if not response or response.status_code != 200:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'message': f\"âŒ HTTPé”™è¯¯æˆ–æ— å“åº”: {response.status_code if response else 'N/A'}\"\n",
    "            }\n",
    "\n",
    "        try:\n",
    "            data = response.json()\n",
    "            if data.get('code') == 0:\n",
    "                vlist = data.get('data', {}).get('list', {}).get('vlist', [])\n",
    "                page_info = data.get('data', {}).get('page', {})\n",
    "\n",
    "                filtered_videos = []\n",
    "                all_videos_info = []\n",
    "\n",
    "                for video in vlist:\n",
    "                    created_time = video.get('created', 0)\n",
    "                    video_info = {\n",
    "                        'created_timestamp': created_time,\n",
    "                        'created_date': self.format_timestamp(created_time),\n",
    "                        'in_range': self.is_video_in_time_range(created_time),\n",
    "                        'video_data': video\n",
    "                    }\n",
    "                    all_videos_info.append(video_info)\n",
    "\n",
    "                    if self.is_video_in_time_range(created_time):\n",
    "                        filtered_videos.append(video)\n",
    "\n",
    "                return {\n",
    "                    'success': True,\n",
    "                    'all_videos': vlist,\n",
    "                    'all_videos_info': all_videos_info,\n",
    "                    'filtered_videos': filtered_videos,\n",
    "                    'total_count': page_info.get('count', 0),\n",
    "                    'current_page': page_info.get('pn', 1),\n",
    "                    'message': f\"âœ… é¡µé¢è·å–{len(vlist)}ä¸ªè§†é¢‘ï¼Œç­›é€‰å{len(filtered_videos)}ä¸ª\"\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    'success': False,\n",
    "                    'message': f\"âŒ APIè¿”å›é”™è¯¯: {data.get('message', 'æœªçŸ¥é”™è¯¯')} (Code: {data.get('code')})\"\n",
    "                }\n",
    "        except json.JSONDecodeError:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'message': \"âŒ JSONè§£æå¤±è´¥\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'message': f\"âŒ è¯·æ±‚å¤„ç†å¼‚å¸¸: {str(e)}\"\n",
    "            }\n",
    "\n",
    "    def generate_api_urls(self, mid, max_pages=50):\n",
    "        print(f\"ğŸ¯ ä¸ºUPä¸» {mid} ç”ŸæˆAPI URLï¼ˆæ—¶é—´èŒƒå›´: {self.start_date} åˆ° {self.end_date}ï¼‰...\")\n",
    "\n",
    "        first_url = self.generate_api_url(mid, 1)\n",
    "        if not first_url:\n",
    "            print(\"âŒ æ— æ³•ç”Ÿæˆç¬¬ä¸€é¡µURL\")\n",
    "            return {}\n",
    "\n",
    "        print(f\"ğŸ“‹ æµ‹è¯•ç¬¬ä¸€é¡µURL...\")\n",
    "        result = self.get_filtered_videos_from_url(first_url)\n",
    "        if not result['success']:\n",
    "            print(f\"âŒ ç¬¬1é¡µæµ‹è¯•å¤±è´¥: {result['message']}\")\n",
    "            print(\"ğŸ”„ å°è¯•é‡æ–°è·å–wbiå¯†é’¥...\")\n",
    "            self.wbi_keys = None\n",
    "            first_url = self.generate_api_url(mid, 1)\n",
    "            if first_url:\n",
    "                result = self.get_filtered_videos_from_url(first_url)\n",
    "                if not result['success']:\n",
    "                    print(f\"âŒ é‡è¯•åä»ç„¶å¤±è´¥: {result['message']}\")\n",
    "                    return {}\n",
    "            else:\n",
    "                return {}\n",
    "\n",
    "        total_videos = result.get('total_count', 0)\n",
    "        filtered_count = len(result.get('filtered_videos', []))\n",
    "        videos_per_page = 40\n",
    "\n",
    "        print(f\"ğŸ“Š ç¬¬ä¸€é¡µç»Ÿè®¡: æ€»è§†é¢‘ {len(result.get('all_videos', []))} ä¸ªï¼Œç­›é€‰å {filtered_count} ä¸ª\")\n",
    "\n",
    "        if total_videos > 0:\n",
    "            actual_pages = (total_videos + videos_per_page - 1) // videos_per_page\n",
    "            print(f\"ğŸ“Š UPä¸»ç»Ÿè®¡: æ€»è§†é¢‘æ•° {total_videos}, é¢„è®¡é¡µæ•° {actual_pages}\")\n",
    "        else:\n",
    "            print(\"ğŸ“Š æ— æ³•è·å–è§†é¢‘æ€»æ•°ï¼Œé»˜è®¤ç”Ÿæˆå‰å‡ é¡µ\")\n",
    "            actual_pages = max_pages\n",
    "\n",
    "        pages_to_generate = min(actual_pages, max_pages)\n",
    "\n",
    "        api_urls = {}\n",
    "        api_urls[1] = first_url\n",
    "\n",
    "        for page in range(2, pages_to_generate + 1):\n",
    "            url = self.generate_api_url(mid, page)\n",
    "            if url:\n",
    "                api_urls[page] = url\n",
    "                print(f\"âœ… ç”Ÿæˆç¬¬{page}é¡µAPI URL\")\n",
    "                time.sleep(7)\n",
    "            else:\n",
    "                print(f\"âŒ ç”Ÿæˆç¬¬{page}é¡µURLå¤±è´¥\")\n",
    "                break\n",
    "\n",
    "        return api_urls\n",
    "\n",
    "    def crawl_videos_from_page_with_time_filter(self, page):\n",
    "        if page not in self.api_urls:\n",
    "            print(f\"ç¬¬ {page} é¡µçš„URLä¸å­˜åœ¨\")\n",
    "            return [], False\n",
    "\n",
    "        url = self.api_urls[page]\n",
    "\n",
    "        result = self.get_filtered_videos_from_url(url)\n",
    "        if not result['success']:\n",
    "            print(f\"ç¬¬ {page} é¡µè·å–å¤±è´¥: {result['message']}\")\n",
    "            return [], False\n",
    "\n",
    "        filtered_vlist = result['filtered_videos']\n",
    "        all_videos_info = result['all_videos_info']\n",
    "\n",
    "        print(result['message'])\n",
    "\n",
    "        should_continue = False\n",
    "        if all_videos_info:\n",
    "            oldest_video_time = min(info['created_timestamp'] for info in all_videos_info)\n",
    "            newest_video_time = max(info['created_timestamp'] for info in all_videos_info)\n",
    "\n",
    "            print(f\"ğŸ“… å½“å‰é¡µè§†é¢‘å‘å¸ƒæ—¶é—´èŒƒå›´: {self.format_timestamp(oldest_video_time)} åˆ° {self.format_timestamp(newest_video_time)}\")\n",
    "\n",
    "            if newest_video_time < self.start_timestamp:\n",
    "                print(f\"â¹ï¸  å½“å‰é¡µé¢æœ€æ–°è§†é¢‘å‘å¸ƒæ—¶é—´æ—©äºç­›é€‰å¼€å§‹æ—¶é—´ï¼Œåœæ­¢æœç´¢åç»­é¡µé¢ã€‚\")\n",
    "                should_continue = False\n",
    "            else:\n",
    "                should_continue = True\n",
    "\n",
    "        if not filtered_vlist and should_continue:\n",
    "            print(f'âš ï¸ ç¬¬ {page} é¡µæ²¡æœ‰ç¬¦åˆæ—¶é—´èŒƒå›´çš„è§†é¢‘ï¼Œä½†æ ¹æ®æ—¶é—´åˆ¤æ–­å¯èƒ½éœ€è¦ç»§ç»­ã€‚')\n",
    "        elif not filtered_vlist and not should_continue:\n",
    "            print(f'â¹ï¸ ç¬¬ {page} é¡µæ²¡æœ‰ç¬¦åˆæ—¶é—´èŒƒå›´çš„è§†é¢‘ï¼Œä¸”å·²è¶…å‡ºæ—¶é—´èŒƒå›´ï¼Œåœæ­¢æœç´¢ã€‚')\n",
    "            return [], False\n",
    "\n",
    "        videos = []\n",
    "        print(f\"ç¬¬ {page} é¡µå¼€å§‹å¤„ç† {len(filtered_vlist)} ä¸ªç¬¦åˆæ—¶é—´èŒƒå›´çš„è§†é¢‘\")\n",
    "\n",
    "        # è°ƒæ•´æ¯ä¸ªè§†é¢‘å¤„ç†åçš„å»¶æ—¶\n",
    "        DEFAULT_VIDEO_PROCESS_SLEEP = 2.5  # ä»3ç§’å‡å°‘åˆ°2ç§’\n",
    "\n",
    "        for i, video_data in enumerate(filtered_vlist):\n",
    "            title = video_data.get('title', 'N/A')\n",
    "            aid = video_data.get('aid')\n",
    "            description = video_data.get('description', 'N/A')\n",
    "            bvid = video_data.get('bvid', 'N/A')\n",
    "            video_url = f\"https://www.bilibili.com/video/{bvid}\"\n",
    "            length = video_data.get('length', 'N/A')\n",
    "            play = video_data.get('play', 0)\n",
    "            comment = video_data.get('comment', 0)\n",
    "            review = video_data.get('video_review', 0)\n",
    "            created = self.timestamp_to_datetime(video_data.get('created', 0))\n",
    "            pic_url = video_data.get('pic', 'N/A')\n",
    "            is_union_video_val = video_data.get('is_union_video', 0)\n",
    "            is_union_video = 'æ˜¯' if is_union_video_val == 1 else 'å¦'\n",
    "\n",
    "            detail_info = self.get_video_detail(aid)\n",
    "            if detail_info:\n",
    "                (like, collect, coin, share, region, mid, name, fans, sign, level_info, duration_seconds,\n",
    "                 pages_count, copyright, video_state, related_count, sex, vip_type, vip_status, nameplate) = detail_info\n",
    "            else:\n",
    "                (like, collect, coin, share, region, mid, name, fans, sign, level_info, duration_seconds,\n",
    "                 pages_count, copyright, video_state, related_count, sex, vip_type, vip_status, nameplate) = (\n",
    "                    'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A',\n",
    "                    'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A'\n",
    "                )\n",
    "\n",
    "            video_info = {\n",
    "                'title': title, 'description': description, 'bvid': bvid, 'video_url': video_url,\n",
    "                'length': length, 'duration_seconds': duration_seconds,\n",
    "                'play': play, 'comment': comment, 'like': like, 'review': review, 'collect': collect,\n",
    "                'coin': coin, 'share': share, 'region': region, 'created': created, 'mid': mid,\n",
    "                'name': name, 'fans': fans, 'sign': sign, 'level_info': level_info,\n",
    "                'pic_url': pic_url, 'is_union_video': is_union_video, 'pages_count': pages_count,\n",
    "                'copyright': copyright, 'video_state': video_state, 'related_count': related_count,\n",
    "                'sex': sex, 'vip_type': vip_type, 'vip_status': vip_status, 'nameplate': nameplate,\n",
    "            }\n",
    "\n",
    "            videos.append(video_info)\n",
    "            print(f\"âœ… å¤„ç†è§†é¢‘ {i+1}/{len(filtered_vlist)}: {title} (å‘å¸ƒäº: {created})\")\n",
    "\n",
    "            time.sleep(DEFAULT_VIDEO_PROCESS_SLEEP)\n",
    "\n",
    "        return videos, should_continue\n",
    "\n",
    "    def save_to_excel(self, videos, filename):\n",
    "        wb = Workbook()\n",
    "        ws = wb.active\n",
    "        ws.title = \"è§†é¢‘åˆ—è¡¨\"\n",
    "\n",
    "        headers = ['è§†é¢‘æ ‡é¢˜', 'è§†é¢‘æè¿°', 'è§†é¢‘BVå·', 'è§†é¢‘URL', 'å°é¢URL', 'è§†é¢‘æ—¶é•¿', 'è§†é¢‘æ—¶é•¿ç§’', 'æ˜¯å¦åˆä½œè§†é¢‘', 'å¤šPæ•°é‡',\n",
    "                   'ç‰ˆæƒ', 'è§†é¢‘çŠ¶æ€', 'ç›¸å…³è§†é¢‘æ•°é‡', 'æ’­æ”¾', 'è¯„è®º', 'ç‚¹èµ', 'å¼¹å¹•', 'æ”¶è—', 'æŠ•å¸', 'åˆ†äº«',\n",
    "                   'æ‰€å±åˆ†åŒº', 'å‘å¸ƒæ—¶é—´','UID','æ˜µç§°', 'æ€§åˆ«', 'ç²‰ä¸æ•°','ç­¾å','æ˜¯å¦è®¤è¯/ç­‰çº§', 'ä¼šå‘˜ç±»å‹', 'ä¼šå‘˜çŠ¶æ€', 'ç²‰ä¸å‹‹ç« ']\n",
    "        ws.append(headers)\n",
    "\n",
    "        for video in videos:\n",
    "            row = [\n",
    "                video.get('title'), video.get('description'), video.get('bvid'), video.get('video_url'),\n",
    "                video.get('pic_url'), video.get('length'), video.get('duration_seconds'), video.get('is_union_video'),\n",
    "                video.get('pages_count'), video.get('copyright'), video.get('video_state'), video.get('related_count'),\n",
    "                video.get('play'), video.get('comment'), video.get('like'), video.get('review'), video.get('collect'),\n",
    "                video.get('coin'), video.get('share'), video.get('region'), video.get('created'), video.get('mid'),\n",
    "                video.get('name'), video.get('sex'), video.get('fans'), video.get('sign'), video.get('level_info'),\n",
    "                video.get('vip_type'), video.get('vip_status'), video.get('nameplate')\n",
    "            ]\n",
    "            ws.append(row)\n",
    "\n",
    "        wb.save(filename)\n",
    "        print(f\"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ° {filename}\")\n",
    "\n",
    "    # --- å•ä¸ªUPä¸»å®Œæ•´å¤„ç† ---\n",
    "    def process_single_up_complete(self, mid, max_pages=50):  # ç§»é™¤include_ai_summaryå‚æ•°\n",
    "        try:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"ğŸ¯ å¼€å§‹å¤„ç†UPä¸»: {mid}\")\n",
    "            print(f\"{'='*60}\")\n",
    "\n",
    "            self.wbi_keys = None  # é‡ç½®WBIå¯†é’¥\n",
    "\n",
    "            up_info = self.get_up_info(mid)\n",
    "            if not up_info:\n",
    "                up_name = f'UPä¸»{mid}'\n",
    "                up_info = {'name': up_name, 'follower': 0, 'video': 0}\n",
    "            else:\n",
    "                up_name = up_info.get('name', f'UPä¸»{mid}')\n",
    "\n",
    "            print(f\"ğŸ‘¤ UPä¸»æ˜µç§°: {up_name}\")\n",
    "            print(f\"ğŸ‘¥ ç²‰ä¸æ•°: {up_info.get('follower', 0):,}\")\n",
    "            print(f\"ğŸ“º æŠ•ç¨¿è§†é¢‘æ•°: {up_info.get('video', 0):,}\")\n",
    "\n",
    "            print(f\"\\nğŸ“‹ ç”ŸæˆAPI URLåˆ—è¡¨...\")\n",
    "            self.api_urls = self.generate_api_urls(mid, max_pages)\n",
    "\n",
    "            if not self.api_urls:\n",
    "                return {\n",
    "                    'success': False,\n",
    "                    'up_name': up_name,\n",
    "                    'up_mid': mid,\n",
    "                    'video_count': 0,\n",
    "                    'error': 'æ— æ³•ç”ŸæˆAPI URLsï¼ˆå¯èƒ½WBIå¯†é’¥è·å–å¤±è´¥æˆ–UPä¸»æ— è§†é¢‘ï¼‰'\n",
    "                }\n",
    "\n",
    "            print(f\"âœ… æˆåŠŸç”Ÿæˆ {len(self.api_urls)} ä¸ªAPI URL\")\n",
    "\n",
    "            print(f\"\\nğŸš€ å¼€å§‹çˆ¬å–æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„è§†é¢‘æ•°æ®...\")\n",
    "            all_videos = []\n",
    "\n",
    "            # è°ƒæ•´è¿™é‡Œçš„é¡µé¢é—´å»¶æ—¶\n",
    "            DEFAULT_PAGE_INTERVAL_SLEEP = 6  # ä»8ç§’å‡å°‘åˆ°5ç§’\n",
    "\n",
    "            for page in sorted(self.api_urls.keys()):\n",
    "                print(f\"\\nğŸ”„ æ­£åœ¨çˆ¬å–ç¬¬ {page} é¡µ...\")\n",
    "                videos_on_page, should_continue = self.crawl_videos_from_page_with_time_filter(page)\n",
    "\n",
    "                if videos_on_page:\n",
    "                    all_videos.extend(videos_on_page)\n",
    "                    print(f\"âœ… ç¬¬ {page} é¡µå®Œæˆï¼Œè·å– {len(videos_on_page)} ä¸ªç¬¦åˆæ—¶é—´èŒƒå›´çš„è§†é¢‘\")\n",
    "                else:\n",
    "                    print(f\"âš ï¸ ç¬¬ {page} é¡µæ²¡æœ‰ç¬¦åˆæ—¶é—´èŒƒå›´çš„è§†é¢‘ã€‚\")\n",
    "\n",
    "                if not should_continue:\n",
    "                    print(f\"ğŸ›‘ å·²è¶…å‡ºæ—¶é—´èŒƒå›´æˆ–æ‰€æœ‰è§†é¢‘å‡å·²å¤„ç†ï¼Œåœæ­¢æœç´¢åç»­é¡µé¢ã€‚å…±æœç´¢äº† {page} é¡µ\")\n",
    "                    break\n",
    "\n",
    "                if page < max(self.api_urls.keys()):\n",
    "                    print(f\"â° é¡µé¢é—´å»¶æ—¶ {DEFAULT_PAGE_INTERVAL_SLEEP} ç§’...\")\n",
    "                    time.sleep(DEFAULT_PAGE_INTERVAL_SLEEP)\n",
    "\n",
    "            if not all_videos:\n",
    "                return {\n",
    "                    'success': False,\n",
    "                    'up_name': up_name,\n",
    "                    'up_mid': mid,\n",
    "                    'video_count': 0,\n",
    "                    'error': 'æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ—¶é—´èŒƒå›´çš„è§†é¢‘ï¼Œæˆ–è§†é¢‘åˆ—è¡¨APIè·å–å¤±è´¥'\n",
    "                }\n",
    "\n",
    "            safe_up_name = sanitize_filename(up_name)  # ä½¿ç”¨å…¨å±€å‡½æ•°\n",
    "            time_range_str = f\"{self.start_date.replace('-', '')}_to_{self.end_date.replace('-', '')}\"\n",
    "            video_filename = f\"{safe_up_name}_{mid}_{time_range_str}_è§†é¢‘åˆ—è¡¨.xlsx\"\n",
    "            self.save_to_excel(all_videos, video_filename)\n",
    "\n",
    "            print(f\"\\nğŸ‰ è§†é¢‘çˆ¬å–å®Œæˆï¼\")\n",
    "            print(f\"ğŸ“Š æ—¶é—´èŒƒå›´å†…çš„è§†é¢‘æ€»æ•°: {len(all_videos)} ä¸ª\")\n",
    "            print(f\"ğŸ“ è§†é¢‘æ–‡ä»¶ä¿å­˜ä¸º: {video_filename}\")\n",
    "\n",
    "            return {\n",
    "                'success': True,\n",
    "                'up_name': up_name,\n",
    "                'up_mid': mid,\n",
    "                'video_count': len(all_videos),\n",
    "                'video_filename': video_filename,\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"å¤„ç†UPä¸»{mid}æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}\"\n",
    "            print(f\"âŒ {error_msg}\")\n",
    "            print(traceback.format_exc())\n",
    "            return {\n",
    "                'success': False,\n",
    "                'up_name': f'UPä¸»{mid}',\n",
    "                'up_mid': mid,\n",
    "                'video_count': 0,\n",
    "                'error': error_msg\n",
    "            }\n",
    "\n",
    "    # --- æ‰¹é‡å¤„ç†ä¸»å‡½æ•° ---\n",
    "    def batch_crawl_up_videos_complete(self, excel_path, start_index=0, end_index=None, max_pages_per_up=50):  # ç§»é™¤include_ai_summaryå‚æ•°\n",
    "        print(\"=\"*100)\n",
    "        print(\"ğŸš€ Bç«™UPä¸»æ‰¹é‡å®Œæ•´çˆ¬å–å·¥å…·ï¼ˆè§†é¢‘ä¿¡æ¯ç‰ˆï¼‰\")\n",
    "        print(\"=\"*100)\n",
    "\n",
    "        # æ£€æŸ¥Cookieæ± \n",
    "        if not self.cookie_strings_pool:\n",
    "            print(\"âŒ Cookieæ± ä¸ºç©ºï¼è¯·åœ¨configä¸­æä¾›æœ‰æ•ˆçš„Cookieå­—ç¬¦ä¸²ã€‚ç¨‹åºå°†é€€å‡ºã€‚\")\n",
    "            return None\n",
    "        print(f\"âœ… Cookieæ± å·²åŠ è½½ï¼Œå…± {len(self.cookie_strings_pool)} ä¸ªCookieã€‚\")\n",
    "\n",
    "        print(\"ğŸ” æµ‹è¯•Cookieæœ‰æ•ˆæ€§ (ä½¿ç”¨æ± ä¸­ç¬¬ä¸€ä¸ªCookie)...\")\n",
    "        is_valid, result = self.test_cookie_validity()\n",
    "\n",
    "        if not is_valid:\n",
    "            print(f\"âŒ ç¬¬ä¸€ä¸ªCookieæ— æ•ˆæˆ–æ— æ³•è¿æ¥åˆ°Bç«™API: {result}\")\n",
    "            print(\"è¯·æ£€æŸ¥æ‚¨çš„ç½‘ç»œè¿æ¥æˆ–æ›´æ–° Cookie å­—ç¬¦ä¸²ã€‚ç¨‹åºå°†é€€å‡ºã€‚\")\n",
    "            return None\n",
    "        else:\n",
    "            print(f\"âœ… Cookieæœ‰æ•ˆï¼å½“å‰ç™»å½•ç”¨æˆ·: {result['username']} (UID: {result['uid']})\")\n",
    "\n",
    "\n",
    "        up_mids = read_up_list_from_excel(excel_path, start_index, end_index)  # ä½¿ç”¨å…¨å±€å‡½æ•°\n",
    "        if not up_mids:\n",
    "            print(\"âŒ æ²¡æœ‰æœ‰æ•ˆçš„UPä¸»IDå¯å¤„ç†\")\n",
    "            return None\n",
    "\n",
    "        print(f\"ğŸ“… æ—¶é—´ç­›é€‰èŒƒå›´: {self.start_date} åˆ° {self.end_date}\")\n",
    "        print(f\"ğŸ“„ æ¯ä¸ªUPä¸»æœ€å¤§çˆ¬å–é¡µæ•°: {max_pages_per_up}\")\n",
    "\n",
    "        total_ups = len(up_mids)\n",
    "        overall_results = []\n",
    "        failed_ups = []\n",
    "\n",
    "        print(f\"\\nğŸ¯ å¼€å§‹æ‰¹é‡å¤„ç† {total_ups} ä¸ªUPä¸»...\")\n",
    "\n",
    "        # è°ƒæ•´è¿™é‡Œçš„UPä¸»é—´å»¶æ—¶\n",
    "        DEFAULT_UP_INTERVAL_SLEEP = 10  # ä»15ç§’å‡å°‘åˆ°10ç§’\n",
    "\n",
    "        for i, mid in enumerate(up_mids, 1):\n",
    "            print(f\"\\n{'ğŸ”¥' * 20}\")\n",
    "            print(f\"è¿›åº¦: [{i}/{total_ups}] å¤„ç†UPä¸»: {mid}\")\n",
    "            print(f\"{'ğŸ”¥' * 20}\")\n",
    "\n",
    "            try:\n",
    "                result = self.process_single_up_complete(mid, max_pages_per_up)  # ç§»é™¤include_ai_summaryå‚æ•°\n",
    "                overall_results.append(result)\n",
    "\n",
    "                if result['success']:\n",
    "                    self.batch_stats['success_count'] += 1\n",
    "                    self.batch_stats['total_videos'] += result['video_count']\n",
    "                    print(f\"âœ… æˆåŠŸ! è·å– {result['video_count']} ä¸ªè§†é¢‘\")\n",
    "                else:\n",
    "                    self.batch_stats['failed_count'] += 1\n",
    "                    failed_ups.append({\n",
    "                        'mid': mid,\n",
    "                        'error': result.get('error', 'æœªçŸ¥é”™è¯¯')\n",
    "                    })\n",
    "                    print(f\"âŒ å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}\")\n",
    "\n",
    "                self.batch_stats['total_processed'] += 1\n",
    "\n",
    "                print(f\"ğŸ“Š å½“å‰ç»Ÿè®¡: æˆåŠŸ {self.batch_stats['success_count']}/{i}, \"\n",
    "                      f\"å¤±è´¥ {self.batch_stats['failed_count']}, \"\n",
    "                      f\"æ€»è§†é¢‘ {self.batch_stats['total_videos']}\")\n",
    "\n",
    "                if i < total_ups:\n",
    "                    print(f\"â° UPä¸»é—´å»¶æ—¶ {DEFAULT_UP_INTERVAL_SLEEP} ç§’...\")\n",
    "                    time.sleep(DEFAULT_UP_INTERVAL_SLEEP)\n",
    "\n",
    "            except Exception as e:\n",
    "                error_msg = f\"å¤„ç†UPä¸»{mid}æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}\"\n",
    "                print(f\"âŒ {error_msg}\")\n",
    "                self.batch_stats['failed_count'] += 1\n",
    "                failed_ups.append({\n",
    "                    'mid': mid,\n",
    "                    'error': error_msg\n",
    "                })\n",
    "                overall_results.append({\n",
    "                    'success': False,\n",
    "                    'up_name': f'UPä¸»{mid}',\n",
    "                    'up_mid': mid,\n",
    "                    'video_count': 0,\n",
    "                    'error': error_msg\n",
    "                })\n",
    "\n",
    "        self.generate_batch_report_complete(overall_results, failed_ups)\n",
    "\n",
    "        return {\n",
    "            'total_processed': self.batch_stats['total_processed'],\n",
    "            'success_count': self.batch_stats['success_count'],\n",
    "            'failed_count': self.batch_stats['failed_count'],\n",
    "            'total_videos': self.batch_stats['total_videos'],\n",
    "            'results': overall_results,\n",
    "            'failed_ups': failed_ups\n",
    "        }\n",
    "\n",
    "    def generate_batch_report_complete(self, results, failed_ups):\n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(\"ğŸ“Š æ‰¹é‡å¤„ç†å®ŒæˆæŠ¥å‘Šï¼ˆè§†é¢‘ä¿¡æ¯ç‰ˆï¼‰\")\n",
    "        print(\"=\"*100)\n",
    "\n",
    "        print(f\"âœ… å¤„ç†å®Œæˆ: {self.batch_stats['total_processed']} ä¸ªUPä¸»\")\n",
    "        print(f\"ğŸ‰ æˆåŠŸ: {self.batch_stats['success_count']} ä¸ª\")\n",
    "        print(f\"âŒ å¤±è´¥: {self.batch_stats['failed_count']} ä¸ª\")\n",
    "        print(f\"ğŸ“º æ€»è§†é¢‘æ•°: {self.batch_stats['total_videos']} ä¸ª\")\n",
    "\n",
    "        if self.batch_stats['success_count'] > 0:\n",
    "            print(f\"\\nâœ… æˆåŠŸå¤„ç†çš„UPä¸»:\")\n",
    "            for result in results:\n",
    "                if result['success']:\n",
    "                    print(f\"  - {result['up_name']} ({result.get('up_mid', 'N/A')}): \"\n",
    "                          f\"{result['video_count']} ä¸ªè§†é¢‘ï¼Œæ–‡ä»¶: {result['video_filename']}\")\n",
    "\n",
    "        if failed_ups:\n",
    "            print(f\"\\nâŒ å¤±è´¥çš„UPä¸»:\")\n",
    "            for failed in failed_ups:\n",
    "                print(f\"  - {failed['mid']}: {failed['error']}\")\n",
    "\n",
    "        report_filename = f\"æ‰¹é‡å¤„ç†æŠ¥å‘Š_è§†é¢‘ä¿¡æ¯ç‰ˆ_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "        try:\n",
    "            with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(\"Bç«™UPä¸»æ‰¹é‡è§†é¢‘ä¿¡æ¯çˆ¬å–å¤„ç†æŠ¥å‘Š\\n\")\n",
    "                f.write(\"=\"*50 + \"\\n\")\n",
    "                f.write(f\"å¤„ç†æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                f.write(f\"æ—¶é—´èŒƒå›´: {self.start_date} åˆ° {self.end_date}\\n\")\n",
    "                f.write(f\"æ€»å¤„ç†æ•°: {self.batch_stats['total_processed']}\\n\")\n",
    "                f.write(f\"æˆåŠŸæ•°: {self.batch_stats['success_count']}\\n\")\n",
    "                f.write(f\"å¤±è´¥æ•°: {self.batch_stats['failed_count']}\\n\")\n",
    "                f.write(f\"æ€»è§†é¢‘æ•°: {self.batch_stats['total_videos']}\\n\\n\")\n",
    "\n",
    "                if self.batch_stats['success_count'] > 0:\n",
    "                    f.write(\"æˆåŠŸå¤„ç†çš„UPä¸»:\\n\")\n",
    "                    for result in results:\n",
    "                        if result['success']:\n",
    "                            f.write(f\"  - {result['up_name']} ({result.get('up_mid', 'N/A')}): \"\n",
    "                                    f\"{result['video_count']} ä¸ªè§†é¢‘ï¼Œæ–‡ä»¶: {result['video_filename']}\\n\")\n",
    "\n",
    "                if failed_ups:\n",
    "                    f.write(\"\\nå¤±è´¥çš„UPä¸»:\\n\")\n",
    "                    for failed in failed_ups:\n",
    "                        f.write(f\"  - {failed['mid']}: {failed['error']}\\n\")\n",
    "\n",
    "            print(f\"ğŸ“„ å¤„ç†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ä¿å­˜æŠ¥å‘Šæ–‡ä»¶å¤±è´¥: {str(e)}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"ä¸»å‡½æ•°\"\"\"\n",
    "    print(\"=\"*100)\n",
    "    print(\"ğŸ¯ Bç«™UPä¸»è§†é¢‘ä¿¡æ¯æ‰¹é‡çˆ¬å–å·¥å…·\")\n",
    "    print(\"=\"*100)\n",
    "\n",
    "    # æ£€æŸ¥é…ç½®\n",
    "    if not CONFIG['cookie_strings_pool'] or not any(c for c in CONFIG['cookie_strings_pool']):\n",
    "        print(\"âŒ è¯·åœ¨CONFIGå­—å…¸ä¸­è®¾ç½®è‡³å°‘ä¸€ä¸ªæœ‰æ•ˆçš„Cookieå­—ç¬¦ä¸²åˆ° 'cookie_strings_pool'!\")\n",
    "        return\n",
    "    if not CONFIG['excel_path']:\n",
    "        print(\"âŒ è¯·åœ¨CONFIGå­—å…¸ä¸­è®¾ç½®ä½ çš„excelæ–‡ä»¶è·¯å¾„!\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- é…ç½®ä¿¡æ¯ ---\")\n",
    "    for key, value in CONFIG.items():\n",
    "        if key == 'cookie_strings_pool':\n",
    "            print(f\"  {key}: å·²é…ç½® {len(value)} ä¸ªCookie\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "    print(\"------------------\\n\")\n",
    "\n",
    "    crawler = BilibiliCrawler(CONFIG)  # ä½¿ç”¨æ–°çš„ç±»å\n",
    "\n",
    "    # é‡è¦çš„Cookieæœ‰æ•ˆæ€§æµ‹è¯•\n",
    "    print(\"\\nğŸš€ æ­£åœ¨æµ‹è¯•Cookieæœ‰æ•ˆæ€§ (ä½¿ç”¨æ± ä¸­ç¬¬ä¸€ä¸ªCookie)...\")\n",
    "    is_valid_cookie, cookie_check_info = crawler.test_cookie_validity()\n",
    "    \n",
    "    if not is_valid_cookie:\n",
    "        print(f\"âŒ ç¬¬ä¸€ä¸ªCookieæ— æ•ˆæˆ–æ— æ³•è¿æ¥åˆ°Bç«™API: {cookie_check_info}\")\n",
    "        print(\"è¯·æ£€æŸ¥æ‚¨çš„ç½‘ç»œè¿æ¥æˆ–æ›´æ–° 'cookie_strings_pool' ä¸­çš„Cookieå­—ç¬¦ä¸²ã€‚ç¨‹åºå°†é€€å‡ºã€‚\")\n",
    "        return\n",
    "    else:\n",
    "        print(f\"âœ… Cookieæœ‰æ•ˆï¼å½“å‰ç™»å½•ç”¨æˆ·: {cookie_check_info.get('username', 'æœªçŸ¥')} (UID: {cookie_check_info.get('uid', 'æœªçŸ¥')})\")\n",
    "\n",
    "\n",
    "    print(f\"\\nğŸ“Š æ­£åœ¨è¯»å–UPä¸»MIDåˆ—è¡¨ä» {CONFIG['excel_path']} (ç´¢å¼•èŒƒå›´: {CONFIG['start_index']} åˆ° {CONFIG['end_index'] if CONFIG['end_index'] is not None else 'æœ«å°¾'})...\")\n",
    "    \n",
    "    result_stats = crawler.batch_crawl_up_videos_complete(\n",
    "        excel_path=CONFIG['excel_path'],\n",
    "        start_index=CONFIG['start_index'],\n",
    "        end_index=CONFIG['end_index'],\n",
    "        max_pages_per_up=CONFIG['max_pages_per_up']\n",
    "    )\n",
    "\n",
    "    if result_stats:\n",
    "        print(f\"\\nğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼\")\n",
    "        print(f\"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:\")\n",
    "        print(f\"  æ€»è®¡å¤„ç†UPä¸»: {result_stats['total_processed']} ä¸ª\")\n",
    "        print(f\"  æˆåŠŸå¤„ç†UPä¸»: {result_stats['success_count']} ä¸ª\")\n",
    "        print(f\"  å¤±è´¥å¤„ç†UPä¸»: {result_stats['failed_count']} ä¸ª\")\n",
    "        print(f\"  è·å–è§†é¢‘æ€»æ•°: {result_stats['total_videos']} ä¸ª\")\n",
    "        if result_stats['failed_ups']:\n",
    "            print(\"\\n  ä»¥ä¸‹UPä¸»å¤„ç†å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æŠ¥å‘Šè·å–è¯¦æƒ…:\")\n",
    "            for f_up in result_stats['failed_ups']:\n",
    "                print(f\"    - MID: {f_up['mid']}, é”™è¯¯: {f_up['error']}\")\n",
    "    else:\n",
    "        print(\"\\nâŒ æ‰¹é‡å¤„ç†å¤±è´¥æˆ–è¢«ä¸­æ­¢ï¼\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "ğŸ¯ Bç«™UPä¸»è§†é¢‘ä¿¡æ¯æ‰¹é‡çˆ¬å–å·¥å…·\n",
      "====================================================================================================\n",
      "\n",
      "--- é…ç½®ä¿¡æ¯ ---\n",
      "  excel_path: F:\\Code\\çˆ¬è™«\\UPä¸»ID.xlsx\n",
      "  cookie_strings_pool: å·²é…ç½® 1 ä¸ªCookie\n",
      "  cookie_rotate_interval_seconds: 900\n",
      "  start_date: 2023-07-01\n",
      "  end_date: 2024-01-31\n",
      "  start_index: 750\n",
      "  end_index: None\n",
      "  max_pages_per_up: 20\n",
      "------------------\n",
      "\n",
      "âœ… Cookieå·²åˆ‡æ¢è‡³æ± ä¸­ç´¢å¼• 0 çš„Cookieã€‚\n",
      "\n",
      "ğŸš€ æ­£åœ¨æµ‹è¯•Cookieæœ‰æ•ˆæ€§ (ä½¿ç”¨æ± ä¸­ç¬¬ä¸€ä¸ªCookie)...\n",
      "âœ… Cookieæœ‰æ•ˆï¼å½“å‰ç™»å½•ç”¨æˆ·: æµ‹è¯•ç”¨è´¦å·114514 (UID: 3546919328549020)\n",
      "\n",
      "ğŸ“Š æ­£åœ¨è¯»å–UPä¸»MIDåˆ—è¡¨ä» F:\\Code\\çˆ¬è™«\\UPä¸»ID.xlsx (ç´¢å¼•èŒƒå›´: 750 åˆ° æœ«å°¾)...\n",
      "====================================================================================================\n",
      "ğŸš€ Bç«™UPä¸»æ‰¹é‡å®Œæ•´çˆ¬å–å·¥å…·ï¼ˆè§†é¢‘ä¿¡æ¯ç‰ˆï¼‰\n",
      "====================================================================================================\n",
      "âœ… Cookieæ± å·²åŠ è½½ï¼Œå…± 1 ä¸ªCookieã€‚\n",
      "ğŸ” æµ‹è¯•Cookieæœ‰æ•ˆæ€§ (ä½¿ç”¨æ± ä¸­ç¬¬ä¸€ä¸ªCookie)...\n",
      "âœ… Cookieæœ‰æ•ˆï¼å½“å‰ç™»å½•ç”¨æˆ·: æµ‹è¯•ç”¨è´¦å·114514 (UID: 3546919328549020)\n",
      "ğŸ“Š æ­£åœ¨è¯»å–Excelæ–‡ä»¶: F:\\Code\\çˆ¬è™«\\UPä¸»ID.xlsx\n",
      "âœ… æˆåŠŸè¯»å–åˆ° 2067 ä¸ªUPä¸»IDã€‚\n",
      "ğŸ¯ é€‰æ‹©å¤„ç†èŒƒå›´: [750:2067]ï¼Œå…± 1317 ä¸ªUPä¸»ã€‚\n",
      "ğŸ“… æ—¶é—´ç­›é€‰èŒƒå›´: 2023-07-01 åˆ° 2024-01-31\n",
      "ğŸ“„ æ¯ä¸ªUPä¸»æœ€å¤§çˆ¬å–é¡µæ•°: 20\n",
      "\n",
      "ğŸ¯ å¼€å§‹æ‰¹é‡å¤„ç† 1317 ä¸ªUPä¸»...\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥\n",
      "è¿›åº¦: [1/1317] å¤„ç†UPä¸»: 3493088737626697\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ å¼€å§‹å¤„ç†UPä¸»: 3493088737626697\n",
      "============================================================\n",
      "è¯¦ç»†ä¿¡æ¯è·å–å¤±è´¥: è®¿é—®æƒé™ä¸è¶³ (Code: -403)\n",
      "ğŸ”„ å°è¯•è·å–åŸºç¡€UPä¸»ä¿¡æ¯...\n",
      "åŸºç¡€ä¿¡æ¯è·å–å¤±è´¥: è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯• (Code: -799)\n",
      "ğŸ”„ å°è¯•ä»è§†é¢‘é¡µé¢è·å–UPä¸»ä¿¡æ¯...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1046\u001B[0m\n\u001B[0;32m   1042\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mâŒ æ‰¹é‡å¤„ç†å¤±è´¥æˆ–è¢«ä¸­æ­¢ï¼\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1045\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m-> 1046\u001B[0m     main()\n",
      "Cell \u001B[1;32mIn[1], line 1023\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m   1018\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mâœ… Cookieæœ‰æ•ˆï¼å½“å‰ç™»å½•ç”¨æˆ·: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcookie_check_info\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124musername\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mæœªçŸ¥\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (UID: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcookie_check_info\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muid\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mæœªçŸ¥\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1021\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mğŸ“Š æ­£åœ¨è¯»å–UPä¸»MIDåˆ—è¡¨ä» \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mCONFIG[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexcel_path\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (ç´¢å¼•èŒƒå›´: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mCONFIG[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstart_index\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m åˆ° \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mCONFIG[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mend_index\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mif\u001B[39;00m\u001B[38;5;250m \u001B[39mCONFIG[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mend_index\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01mis\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01melse\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mæœ«å°¾\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1023\u001B[0m result_stats \u001B[38;5;241m=\u001B[39m crawler\u001B[38;5;241m.\u001B[39mbatch_crawl_up_videos_complete(\n\u001B[0;32m   1024\u001B[0m     excel_path\u001B[38;5;241m=\u001B[39mCONFIG[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexcel_path\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m   1025\u001B[0m     start_index\u001B[38;5;241m=\u001B[39mCONFIG[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstart_index\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m   1026\u001B[0m     end_index\u001B[38;5;241m=\u001B[39mCONFIG[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mend_index\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m   1027\u001B[0m     max_pages_per_up\u001B[38;5;241m=\u001B[39mCONFIG[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_pages_per_up\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m   1028\u001B[0m )\n\u001B[0;32m   1030\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result_stats:\n\u001B[0;32m   1031\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[1], line 881\u001B[0m, in \u001B[0;36mBilibiliCrawler.batch_crawl_up_videos_complete\u001B[1;34m(self, excel_path, start_index, end_index, max_pages_per_up)\u001B[0m\n\u001B[0;32m    878\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mğŸ”¥\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m20\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    880\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 881\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_single_up_complete(mid, max_pages_per_up)  \u001B[38;5;66;03m# ç§»é™¤include_ai_summaryå‚æ•°\u001B[39;00m\n\u001B[0;32m    882\u001B[0m     overall_results\u001B[38;5;241m.\u001B[39mappend(result)\n\u001B[0;32m    884\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msuccess\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n",
      "Cell \u001B[1;32mIn[1], line 748\u001B[0m, in \u001B[0;36mBilibiliCrawler.process_single_up_complete\u001B[1;34m(self, mid, max_pages)\u001B[0m\n\u001B[0;32m    744\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m60\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    746\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwbi_keys \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m  \u001B[38;5;66;03m# é‡ç½®WBIå¯†é’¥\u001B[39;00m\n\u001B[1;32m--> 748\u001B[0m up_info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_up_info(mid)\n\u001B[0;32m    749\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m up_info:\n\u001B[0;32m    750\u001B[0m     up_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUPä¸»\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmid\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n",
      "Cell \u001B[1;32mIn[1], line 390\u001B[0m, in \u001B[0;36mBilibiliCrawler.get_up_info\u001B[1;34m(self, mid)\u001B[0m\n\u001B[0;32m    388\u001B[0m first_url \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate_api_url(mid, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    389\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m first_url:\n\u001B[1;32m--> 390\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(first_url)\n\u001B[0;32m    391\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m response \u001B[38;5;129;01mand\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m200\u001B[39m:\n\u001B[0;32m    392\u001B[0m         data \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mjson()\n",
      "Cell \u001B[1;32mIn[1], line 209\u001B[0m, in \u001B[0;36mBilibiliCrawler._make_request\u001B[1;34m(self, url, method, params, data, json_data, extra_headers)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m method\u001B[38;5;241m.\u001B[39mupper() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGET\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 209\u001B[0m         response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mget(\n\u001B[0;32m    210\u001B[0m             url,\n\u001B[0;32m    211\u001B[0m             headers\u001B[38;5;241m=\u001B[39mrequest_headers,\n\u001B[0;32m    212\u001B[0m             cookies\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcookies,  \u001B[38;5;66;03m# ä½¿ç”¨self.cookieså¯¹è±¡ï¼Œå®ƒä¼šåœ¨_set_current_cookieä¸­æ›´æ–°\u001B[39;00m\n\u001B[0;32m    213\u001B[0m             params\u001B[38;5;241m=\u001B[39mparams,\n\u001B[0;32m    214\u001B[0m             timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mDEFAULT_REQUEST_TIMEOUT  \u001B[38;5;66;03m# ä½¿ç”¨ç±»å±æ€§\u001B[39;00m\n\u001B[0;32m    215\u001B[0m         )\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m method\u001B[38;5;241m.\u001B[39mupper() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPOST\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    217\u001B[0m         response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mpost(\n\u001B[0;32m    218\u001B[0m             url,\n\u001B[0;32m    219\u001B[0m             headers\u001B[38;5;241m=\u001B[39mrequest_headers,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    224\u001B[0m             timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mDEFAULT_REQUEST_TIMEOUT  \u001B[38;5;66;03m# ä½¿ç”¨ç±»å±æ€§\u001B[39;00m\n\u001B[0;32m    225\u001B[0m         )\n",
      "File \u001B[1;32mF:\\Anaconda\\Lib\\site-packages\\requests\\api.py:73\u001B[0m, in \u001B[0;36mget\u001B[1;34m(url, params, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(url, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     63\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request.\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \n\u001B[0;32m     65\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m request(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mget\u001B[39m\u001B[38;5;124m\"\u001B[39m, url, params\u001B[38;5;241m=\u001B[39mparams, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mF:\\Anaconda\\Lib\\site-packages\\requests\\api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[1;34m(method, url, **kwargs)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[1;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m session\u001B[38;5;241m.\u001B[39mrequest(method\u001B[38;5;241m=\u001B[39mmethod, url\u001B[38;5;241m=\u001B[39murl, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mF:\\Anaconda\\Lib\\site-packages\\requests\\sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[0;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[0;32m    587\u001B[0m }\n\u001B[0;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[1;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msend(prep, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msend_kwargs)\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[1;32mF:\\Anaconda\\Lib\\site-packages\\requests\\sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[0;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[1;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m adapter\u001B[38;5;241m.\u001B[39msend(request, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[0;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[1;32mF:\\Anaconda\\Lib\\site-packages\\requests\\adapters.py:667\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    664\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m TimeoutSauce(connect\u001B[38;5;241m=\u001B[39mtimeout, read\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[0;32m    666\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 667\u001B[0m     resp \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39murlopen(\n\u001B[0;32m    668\u001B[0m         method\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mmethod,\n\u001B[0;32m    669\u001B[0m         url\u001B[38;5;241m=\u001B[39murl,\n\u001B[0;32m    670\u001B[0m         body\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mbody,\n\u001B[0;32m    671\u001B[0m         headers\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mheaders,\n\u001B[0;32m    672\u001B[0m         redirect\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    673\u001B[0m         assert_same_host\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    674\u001B[0m         preload_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    675\u001B[0m         decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    676\u001B[0m         retries\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_retries,\n\u001B[0;32m    677\u001B[0m         timeout\u001B[38;5;241m=\u001B[39mtimeout,\n\u001B[0;32m    678\u001B[0m         chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[0;32m    679\u001B[0m     )\n\u001B[0;32m    681\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    682\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "File \u001B[1;32mF:\\Anaconda\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[0;32m    786\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    788\u001B[0m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[1;32m--> 789\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(\n\u001B[0;32m    790\u001B[0m     conn,\n\u001B[0;32m    791\u001B[0m     method,\n\u001B[0;32m    792\u001B[0m     url,\n\u001B[0;32m    793\u001B[0m     timeout\u001B[38;5;241m=\u001B[39mtimeout_obj,\n\u001B[0;32m    794\u001B[0m     body\u001B[38;5;241m=\u001B[39mbody,\n\u001B[0;32m    795\u001B[0m     headers\u001B[38;5;241m=\u001B[39mheaders,\n\u001B[0;32m    796\u001B[0m     chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[0;32m    797\u001B[0m     retries\u001B[38;5;241m=\u001B[39mretries,\n\u001B[0;32m    798\u001B[0m     response_conn\u001B[38;5;241m=\u001B[39mresponse_conn,\n\u001B[0;32m    799\u001B[0m     preload_content\u001B[38;5;241m=\u001B[39mpreload_content,\n\u001B[0;32m    800\u001B[0m     decode_content\u001B[38;5;241m=\u001B[39mdecode_content,\n\u001B[0;32m    801\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mresponse_kw,\n\u001B[0;32m    802\u001B[0m )\n\u001B[0;32m    804\u001B[0m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n\u001B[0;32m    805\u001B[0m clean_exit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mF:\\Anaconda\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[0;32m    534\u001B[0m \u001B[38;5;66;03m# Receive the response from the server\u001B[39;00m\n\u001B[0;32m    535\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 536\u001B[0m     response \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39mgetresponse()\n\u001B[0;32m    537\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (BaseSSLError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    538\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mread_timeout)\n",
      "File \u001B[1;32mF:\\Anaconda\\Lib\\site-packages\\urllib3\\connection.py:507\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    504\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mresponse\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HTTPResponse\n\u001B[0;32m    506\u001B[0m \u001B[38;5;66;03m# Get the response from http.client.HTTPConnection\u001B[39;00m\n\u001B[1;32m--> 507\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mgetresponse()\n\u001B[0;32m    509\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    510\u001B[0m     assert_header_parsing(httplib_response\u001B[38;5;241m.\u001B[39mmsg)\n",
      "File \u001B[1;32mF:\\Anaconda\\Lib\\http\\client.py:1428\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1426\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1427\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1428\u001B[0m         response\u001B[38;5;241m.\u001B[39mbegin()\n\u001B[0;32m   1429\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[0;32m   1430\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32mF:\\Anaconda\\Lib\\http\\client.py:331\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    329\u001B[0m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[0;32m    330\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 331\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read_status()\n\u001B[0;32m    332\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n\u001B[0;32m    333\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32mF:\\Anaconda\\Lib\\http\\client.py:292\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    291\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 292\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp\u001B[38;5;241m.\u001B[39mreadline(_MAXLINE \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    293\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[0;32m    294\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mF:\\Anaconda\\Lib\\socket.py:707\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    705\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 707\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sock\u001B[38;5;241m.\u001B[39mrecv_into(b)\n\u001B[0;32m    708\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[0;32m    709\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mF:\\Anaconda\\Lib\\ssl.py:1252\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[1;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[0;32m   1248\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1249\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1250\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   1251\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[1;32m-> 1252\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(nbytes, buffer)\n\u001B[0;32m   1253\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1254\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[1;32mF:\\Anaconda\\Lib\\ssl.py:1104\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[1;34m(self, len, buffer)\u001B[0m\n\u001B[0;32m   1102\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1103\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1104\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m, buffer)\n\u001B[0;32m   1105\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1106\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c41e935-8d4d-4cca-85f0-e208620fa49d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
